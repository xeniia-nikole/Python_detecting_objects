{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2UzO5yTFRacmJmDTs89mU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xeniia-nikole/Python_detecting_objects/blob/master/searching_in_video_by_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opencv-python\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from IPython.display import Image \n",
        "from IPython import display\n",
        "\n",
        "path = '/content/'\n",
        "video = path + 'video_budgies.mp4'"
      ],
      "metadata": {
        "id": "SO5hJwOCXFE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load names of classes and get random colors\n",
        "labels = open(path + 'coco.names').read().strip().split('\\n')\n",
        "np.random.seed(42)\n",
        "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "4ZmdlN0u8PnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give the configuration and weight files for the model and load the network.\n",
        "net = cv2.dnn.readNet(path + 'yolov3.weights',\n",
        "                path + 'yolov3.cfg')\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)"
      ],
      "metadata": {
        "id": "m5TSQK1q8Tjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def searching(image, output_layers):\n",
        "    admissible_crossing = 0.5\n",
        "    confidence_level = 0.01\n",
        "    H, W = image.shape[:2]\n",
        "\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    probabilities = []\n",
        "\n",
        "    for layer in output_layers:\n",
        "        probability = layer[5:]\n",
        "        index_max_probability = np.argmax(probability)\n",
        "        confidence = probability[index_max_probability]\n",
        "        if confidence > confidence_level:\n",
        "            x, y, w, h = layer[:4] * np.array([W, H, W, H])\n",
        "            p0 = int(x - w//2), int(y - h//2)\n",
        "            p1 = int(x + w//2), int(y + h//2)\n",
        "            boxes.append([*p0, int(w), int(h)])\n",
        "            confidences.append(float(confidence))\n",
        "            probabilities.append(index_max_probability)\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_level, admissible_crossing)\n",
        "\n",
        "    if len(indices) > 0:\n",
        "        for i in indices.flatten():\n",
        "            (x, y) = (boxes[i][0], boxes[i][1])\n",
        "            (w, h) = (boxes[i][2], boxes[i][3])\n",
        "            color = [int(c) for c in colors[probabilities[i]]]\n",
        "            image_new = cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "            text = \"{}: {:.4f}\".format(labels[probabilities[i]], confidences[i])\n",
        "            image_new = cv2.putText(image_new, text, (x, y - 5), cv2.FONT_HERSHEY_TRIPLEX, 0.5, color, 1)\n",
        "            return image_new"
      ],
      "metadata": {
        "id": "O0QAxuI67ytg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_yolo(image):\n",
        "  height, width, depth = image.shape\n",
        "\n",
        "  blob = cv2.dnn.blobFromImage(image, 1/255.0, (608, 608), swapRB = True, crop=False)\n",
        "  net.setInput(blob)\n",
        "\n",
        "  # determine the output layer\n",
        "  layers_names = net.getLayerNames()\n",
        "  unconnected_layers = net.getUnconnectedOutLayersNames()\n",
        "  output_layers = np.vstack(net.forward(unconnected_layers))\n",
        "  frame_new = searching(image, output_layers)\n",
        "  return frame_new"
      ],
      "metadata": {
        "id": "56CVgwFls1J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update video\n",
        "size = (1280, 720)\n",
        "codec = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "writer = cv2.VideoWriter(path + 'video_new.avi', codec, 5, size)\n",
        "\n",
        "cap = cv2.VideoCapture(video)\n",
        "\n",
        "while cap.isOpened():\n",
        "  print('.', end = '')\n",
        "\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  frame = apply_yolo(frame)\n",
        "  writer.write(frame)\n",
        "\n",
        "cap.release()\n",
        "writer.release()"
      ],
      "metadata": {
        "id": "O_rPnWE6h1PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "gmA-TLtVYUdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Print in project\n",
        "# cap = cv2.VideoCapture(path)\n",
        "\n",
        "# while cap.isOpened():\n",
        "#   ret, frame = cap.read()\n",
        "#   if not ret:\n",
        "#     break\n",
        "#   pyplot.figure(figsize=(15, 10))\n",
        "\n",
        "#   frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#   frame = apply_yolo(frame)\n",
        "\n",
        "#   pyplot.imshow(frame)\n",
        "#   display.clear_output(wait=True)\n",
        "#   display.display(pyplot.gcf())\n",
        "\n",
        "# cap.release()"
      ],
      "metadata": {
        "id": "IDaP-w2hjRSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}